"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.DatabricksArtifactsClient = void 0;
const trace_data_1 = require("../../core/entities/trace_data");
const json_1 = require("../../core/utils/json");
const spec_1 = require("../spec");
const utils_1 = require("../utils");
class DatabricksArtifactsClient {
    constructor(options) {
        this.host = options.host;
        this.databricksToken = options.databricksToken;
    }
    /**
     * Upload trace data (spans) to the backend using artifact repository pattern.
     *
     * 1. Get credentials for upload
     * 2. Serialize trace data to JSON
     * 3. Upload to cloud storage using the credentials
     */
    async uploadTraceData(traceInfo, traceData) {
        try {
            const credentials = await this.getCredentialsForTraceDataUpload(traceInfo.traceId);
            const traceDataJson = json_1.JSONBig.stringify(traceData.toJson());
            await this.uploadToCloudStorage(credentials, traceDataJson);
        }
        catch (error) {
            console.error(`Trace data upload failed for ${traceInfo.traceId}:`, error);
            throw error;
        }
    }
    /**
     * Download trace data (spans) from cloud storage
     * Uses artifact repository pattern with signed URLs
     */
    async downloadTraceData(traceInfo) {
        try {
            const credentials = await this.getCredentialsForTraceDataDownload(traceInfo.traceId);
            const traceDataJson = await this.downloadFromSignedUrl(credentials);
            return trace_data_1.TraceData.fromJson(traceDataJson);
        }
        catch (error) {
            console.error(`Failed to download trace data for ${traceInfo.traceId}:`, error);
            // Return empty trace data if download fails
            // This allows getting trace info even if data is missing
            return new trace_data_1.TraceData([]);
        }
    }
    /**
     * Get credentials for uploading trace data
     * Endpoint: GET /api/2.0/mlflow/traces/{request_id}/credentials-for-data-upload
     */
    async getCredentialsForTraceDataUpload(traceId) {
        const url = spec_1.GetCredentialsForTraceDataUpload.getEndpoint(this.host, traceId);
        const response = await (0, utils_1.makeRequest)('GET', url, (0, utils_1.getRequestHeaders)(this.databricksToken));
        return response.credential_info;
    }
    /**
     * Get credentials for downloading trace data
     * Endpoint: GET /mlflow/traces/{trace_id}/credentials-for-data-download
     */
    async getCredentialsForTraceDataDownload(traceId) {
        const url = spec_1.GetCredentialsForTraceDataDownload.getEndpoint(this.host, traceId);
        const response = await (0, utils_1.makeRequest)('GET', url, (0, utils_1.getRequestHeaders)(this.databricksToken));
        if (response.credential_info) {
            return response.credential_info;
        }
        else {
            throw new Error('Invalid response format: missing credential_info');
        }
    }
    /**
     * Upload data to cloud storage using the provided credentials
     */
    async uploadToCloudStorage(credentials, data) {
        const headers = {
            'Content-Type': 'application/json'
        };
        // Add headers from credentials (if they exist)
        if (credentials.headers && Array.isArray(credentials.headers)) {
            credentials.headers.forEach((header) => {
                headers[header.name] = header.value;
            });
        }
        switch (credentials.type) {
            case 'AWS_PRESIGNED_URL':
            case 'GCP_SIGNED_URL':
                await this.uploadToSignedUrl(credentials.signed_uri, data, headers, credentials.type);
                break;
            case 'AZURE_SAS_URI':
                await this.uploadToAzureBlob(credentials.signed_uri, data, headers);
                break;
            case 'AZURE_ADLS_GEN2_SAS_URI':
                await this.uploadToAzureAdlsGen2(credentials.signed_uri, data, headers);
                break;
            default:
                throw new Error(`Unsupported credential type: ${credentials.type}`);
        }
    }
    /**
     * Upload data to cloud storage using signed URL (AWS S3 or GCP Storage)
     */
    async uploadToSignedUrl(signedUrl, data, headers, credentialType) {
        try {
            const response = await fetch(signedUrl, {
                method: 'PUT',
                headers,
                body: data
            });
            if (!response.ok) {
                throw new Error(`${credentialType} upload failed: ${response.status} ${response.statusText}`);
            }
        }
        catch (error) {
            throw new Error(`Failed to upload to ${credentialType}: ${error.message}`);
        }
    }
    /**
     * Upload data to Azure Blob Storage using SAS URI
     * Uses simple PUT for all uploads since traces rarely exceed 100MB
     * https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview
     */
    async uploadToAzureBlob(sasUri, data, headers) {
        try {
            const response = await fetch(sasUri, {
                method: 'PUT',
                headers: {
                    ...headers,
                    'x-ms-blob-type': 'BlockBlob',
                    'Content-Type': 'application/json'
                },
                body: data
            });
            if (!response.ok) {
                throw new Error(`Azure Blob upload failed: ${response.status} ${response.statusText}`);
            }
        }
        catch (error) {
            throw new Error(`Failed to upload to Azure Blob Storage: ${error.message}`);
        }
    }
    /**
     * Upload data to Azure Data Lake Storage Gen2 using SAS URI
     * https://learn.microsoft.com/en-us/rest/api/storageservices/data-lake-storage-gen2
     */
    async uploadToAzureAdlsGen2(sasUri, data, headers) {
        try {
            const dataBuffer = new TextEncoder().encode(data);
            // ADLS Gen2 uses a different API pattern - create file then append data
            // Create the file
            const createUrl = `${sasUri}&resource=file`;
            const createResponse = await fetch(createUrl, {
                method: 'PUT',
                headers: {
                    ...headers,
                    'Content-Length': '0'
                }
            });
            if (!createResponse.ok) {
                throw new Error(`Azure ADLS Gen2 file creation failed: ${createResponse.status} ${createResponse.statusText}`);
            }
            // Append data to the file
            const appendUrl = `${sasUri}&action=append&position=0`;
            const appendResponse = await fetch(appendUrl, {
                method: 'PATCH',
                headers: {
                    ...headers,
                    'Content-Type': 'application/octet-stream'
                },
                body: dataBuffer
            });
            if (!appendResponse.ok) {
                throw new Error(`Azure ADLS Gen2 data append failed: ${appendResponse.status} ${appendResponse.statusText}`);
            }
            // Flush the data to complete the upload
            const flushUrl = `${sasUri}&action=flush&position=${dataBuffer.length}`;
            const flushResponse = await fetch(flushUrl, {
                method: 'PATCH',
                headers: {
                    ...headers,
                    'Content-Length': '0'
                }
            });
            if (!flushResponse.ok) {
                throw new Error(`Azure ADLS Gen2 flush failed: ${flushResponse.status} ${flushResponse.statusText}`);
            }
        }
        catch (error) {
            throw new Error(`Failed to upload to Azure ADLS Gen2: ${error.message}`);
        }
    }
    /**
     * Download data from cloud storage using signed URL
     */
    async downloadFromSignedUrl(credentials) {
        const headers = {};
        // Add headers from credentials (if they exist)
        if (credentials.headers && Array.isArray(credentials.headers)) {
            credentials.headers.forEach((header) => {
                headers[header.name] = header.value;
            });
        }
        try {
            const response = await fetch(credentials.signed_uri, {
                method: 'GET',
                headers
            });
            if (!response.ok) {
                if (response.status === 404) {
                    throw new Error(`Trace data not found (404)`);
                }
                throw new Error(`Download failed: ${response.status} ${response.statusText}`);
            }
            const textData = await response.text();
            try {
                return json_1.JSONBig.parse(textData);
            }
            catch (parseError) {
                throw new Error(`Trace data corrupted: invalid JSON - ${parseError.message}`);
            }
        }
        catch (error) {
            if (error instanceof Error) {
                throw error;
            }
            throw new Error(`Failed to download trace data: ${String(error)}`);
        }
    }
}
exports.DatabricksArtifactsClient = DatabricksArtifactsClient;
